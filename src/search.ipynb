{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0a9fe6798b56496b95185d168ad84764","f4b6edd4473d4ef2b80ff8a18ae4693d","363c9885b33e45dfabab6736d39d47f4","b08b0ea16c0b4976970246ffb55ddf8c","b2f29729439f459ea96ef5fc406666fb","c6c7b5f2fa984966940ea3c5924faf14","29fa28ba06a3446aa24ab16ece7c5867","01d81ca7a6d6454ba47dc29c10f77e22","48fc7d0a4f2b48d1bd79b7d999beb634","d763d299ef62407eb8b8eb0cab12e2ca","c73ef0d61c81402ea165dfa207771e25","24cee2b5dc374df09f33880cbbe2e155","c0671584f5b044b1a4f0b52c3871e106","481d3de38b0240b88f5b74716f0de037","da5cf922faec4fa885eb376c4dded6fe","8a7c7f8bdde64f498335e83c971397b7","5ca9fa949f894cc69951bf3df9a8a142","9a8cbe06ab824e6c8d0d840aac9acb1d","c0e423b1e7714a19ad0f57be5ff94c4c","f6f548fbac5c48a19d6e0953d60c7d6d","6a58957a510849bc984de440425eb495","e1356c5568424d4a808b14d89b692396"]},"id":"wAjFzudCeVK0","outputId":"f0f2f956-5390-49ce-a469-2aa603e367e2","executionInfo":{"status":"error","timestamp":1749147239022,"user_tz":420,"elapsed":713874,"user":{"displayName":"Jayson Meribe","userId":"18347816154755748104"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://download.pytorch.org/whl/cu118\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.87)\n","Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch) (11.11.3.6)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.0.86)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.1.48)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.5.86)\n","Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch) (11.8.86)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: x-transformers in /usr/local/lib/python3.11/dist-packages (2.3.12)\n","Requirement already satisfied: einops>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from x-transformers) (0.8.1)\n","Requirement already satisfied: einx>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from x-transformers) (0.3.0)\n","Requirement already satisfied: loguru in /usr/local/lib/python3.11/dist-packages (from x-transformers) (0.7.3)\n","Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.11/dist-packages (from x-transformers) (24.2)\n","Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from x-transformers) (2.6.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from einx>=0.3.0->x-transformers) (2.0.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from einx>=0.3.0->x-transformers) (1.13.1)\n","Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx>=0.3.0->x-transformers) (2.4.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (11.8.89)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (11.8.87)\n","Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (11.11.3.6)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (10.3.0.86)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (11.4.1.48)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (11.7.5.86)\n","Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (11.8.86)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->x-transformers) (3.2.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->einx>=0.3.0->x-transformers) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->x-transformers) (3.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n","Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjmeribe\u001b[0m (\u001b[33mstanford-curis-jmeribe\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["Hyperparameter search:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a9fe6798b56496b95185d168ad84764"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.11"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250605_180344-p8jbiwwy</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/stanford-curis-jmeribe/generating-imu-data-two/runs/p8jbiwwy' target=\"_blank\">volcanic-sky-210</a></strong> to <a href='https://wandb.ai/stanford-curis-jmeribe/generating-imu-data-two' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/stanford-curis-jmeribe/generating-imu-data-two' target=\"_blank\">https://wandb.ai/stanford-curis-jmeribe/generating-imu-data-two</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/stanford-curis-jmeribe/generating-imu-data-two/runs/p8jbiwwy' target=\"_blank\">https://wandb.ai/stanford-curis-jmeribe/generating-imu-data-two/runs/p8jbiwwy</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["W0605 18:03:50.091000 2369 torch/_dynamo/variables/builtin.py:783] [0/0] incorrect arg count <bound method BuiltinVariable.call_next of BuiltinVariable(next)> too many positional arguments and no constant handler\n","W0605 18:03:56.041000 2369 torch/_dynamo/variables/builtin.py:783] [1/0] incorrect arg count <bound method BuiltinVariable.call_next of BuiltinVariable(next)> too many positional arguments and no constant handler\n","W0605 18:03:57.329000 2369 torch/_inductor/utils.py:1137] [2/0] Not enough SMs to use max_autotune_gemm mode\n","W0605 18:04:00.366000 2369 torch/_dynamo/variables/builtin.py:783] [0/1] incorrect arg count <bound method BuiltinVariable.call_next of BuiltinVariable(next)> too many positional arguments and no constant handler\n","W0605 18:04:01.692000 2369 torch/_dynamo/variables/builtin.py:783] [1/1] incorrect arg count <bound method BuiltinVariable.call_next of BuiltinVariable(next)> too many positional arguments and no constant handler\n","W0605 18:04:04.605000 2369 torch/_dynamo/convert_frame.py:906] [5/8] torch._dynamo hit config.cache_size_limit (8)\n","W0605 18:04:04.605000 2369 torch/_dynamo/convert_frame.py:906] [5/8]    function: 'rearrange' (/usr/local/lib/python3.11/dist-packages/einops/einops.py:545)\n","W0605 18:04:04.605000 2369 torch/_dynamo/convert_frame.py:906] [5/8]    last reason: 5/0: tensor 'L['tensor']' size mismatch at index 0. expected 4063, actual 3702\n","W0605 18:04:04.605000 2369 torch/_dynamo/convert_frame.py:906] [5/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n","W0605 18:04:04.605000 2369 torch/_dynamo/convert_frame.py:906] [5/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n"]},{"output_type":"display_data","data":{"text/plain":["Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24cee2b5dc374df09f33880cbbe2e155"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["W0605 18:04:49.143000 2369 torch/_dynamo/variables/builtin.py:783] [0/2] incorrect arg count <bound method BuiltinVariable.call_next of BuiltinVariable(next)> too many positional arguments and no constant handler\n","W0605 18:04:55.791000 2369 torch/_dynamo/variables/builtin.py:783] [1/2] incorrect arg count <bound method BuiltinVariable.call_next of BuiltinVariable(next)> too many positional arguments and no constant handler\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-346b94ffa795>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m       \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-346b94ffa795>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m           \u001b[0;31m# 3) scale, backward, step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m           \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m           \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install x-transformers\n","!pip install matplotlib\n","!pip install einops\n","!pip install wandb\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!cd /content/drive/MyDrive/realistic-imu/src\n","\n","import wandb\n","wandb.login()\n","\n","import csv\n","import matplotlib.pyplot as plt\n","import os\n","import sys\n","import wandb\n","import pickle\n","import re\n","import itertools\n","\n","# Add the source directory to the system path\n","sys.path.append('/content/drive/MyDrive/realistic-imu/src')\n","\n","from trase_dataset import TraseDataset\n","from trase import Trase, TraseLoss\n","\n","\n","if 'ipykernel' in sys.modules:\n","    from tqdm.notebook import tqdm\n","else:\n","    from tqdm import tqdm\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torch.amp import autocast, GradScaler\n","from torch.utils.data import DataLoader\n","from torch.profiler import profile, record_function, ProfilerActivity\n","\n","\n","torch.cuda.empty_cache()\n","\n","torch.set_float32_matmul_precision('high')\n","\n","device = torch.device(\"cuda\")\n","EPOCHS = 100\n","LEARNING_RATE = 1e-5\n","WEIGHT_DECAY = 1e-4\n","data_path = \"/content/drive/MyDrive/beyondamass/data/realistic-imu-dataset/\"\n","base_path = \"/content/drive/MyDrive/beyondamass/data/realistic-imu-dataset/models\"\n","D_MODEL = 2048\n","INPUT_EMBEDDING_DIM = 408\n","NUM_ENCODERS = 1\n","FEED_FORWARD_DIM = 2048\n","DROPOUT = 0.1\n","HEADS = 8\n","TOTAL_VAR_WEIGHT = 0\n","\n","class CheckpointSaver:\n","    def __init__(self, model, initial_best_loss=float(\"inf\")):\n","        self.best_dev_loss = initial_best_loss\n","        self.model = model\n","\n","    def save_checkpoint(self, dev_loss: float):\n","        # dev_loss is now guaranteed to be a float\n","        if dev_loss <= self.best_dev_loss:\n","            os.makedirs(f\"weights/models-{wandb.run.name}\", exist_ok=True)\n","            torch.save(self.model.state_dict(),\n","                       f\"weights/models-{wandb.run.name}/best.pt\")\n","            wandb.save(f\"weights/models-{wandb.run.name}/best.pt\", policy=\"end\")\n","            self.best_dev_loss = dev_loss\n","            wandb.log({\"best_dev_loss\": dev_loss})\n","\n","        wandb.log({\"dev_loss\": dev_loss})\n","\n","\n","train_path = os.path.join(data_path, \"train.pkl\")\n","dev_path = os.path.join(data_path, \"dev.pkl\")\n","test_path = os.path.join(data_path, \"test.pkl\")\n","\n","train_dataset = TraseDataset(train_path)\n","dev_dataset = TraseDataset(dev_path)\n","# test_dataset = TraseDataset(test_path)\n","\n","identity_collate = lambda batch: batch\n","\n","\n","train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=identity_collate)\n","dev_loader = DataLoader(dev_dataset, batch_size=1, shuffle=False, collate_fn=identity_collate)\n","# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","criterion = TraseLoss(total_var_weight=TOTAL_VAR_WEIGHT)\n","\n","\n","# Grid\n","weight_decays     = [1e-3]\n","learning_rates    = [1e-5]\n","num_encoders_list = [6]\n","\n","param_grid = list(itertools.product(\n","    weight_decays,\n","    learning_rates,\n","    num_encoders_list,\n","))\n","\n","results = []\n","for wd, lr, ne in tqdm(param_grid, desc=\"Hyperparameter search\"):\n","  run = wandb.init(\n","      project=\"generating-imu-data-two\",\n","      config={\n","          \"learning_rate\": lr,\n","          \"epochs\": EPOCHS,\n","          \"weight_decay\": wd,\n","          \"d_model\": D_MODEL,\n","          \"input_embedding_dim\": INPUT_EMBEDDING_DIM,\n","          \"num_encoders\": ne,\n","          \"feed_forward_dim\": FEED_FORWARD_DIM,\n","          \"dropout\": 0,\n","          \"heads\": HEADS,\n","          \"total_var_weight\": TOTAL_VAR_WEIGHT\n","      }\n","  )\n","\n","  model = Trase(d_model=D_MODEL,\n","              inp_emb_dim=INPUT_EMBEDDING_DIM,\n","              device=device,\n","              num_encoders=ne,\n","              dim_feed_forward=FEED_FORWARD_DIM,\n","              heads=HEADS).to(device)\n","\n","  model = torch.compile(model)\n","\n","  saver = CheckpointSaver(model)\n","\n","  optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n","  scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n","\n","  # 1) create a GradScaler for mixed precision\n","  scaler = GradScaler()\n","\n","  def train_model():\n","      curr_loss = 0.0\n","      model.train()\n","\n","      for data in train_loader:\n","          data = data[0]\n","          mocap_data = data[\"inputs\"].to(device)\n","          real_acc = data[\"accelerations_output\"].to(device)\n","          real_angular_vel = (data[\"angular_velocities_output\"].to(device)\n","                              if data[\"angular_velocities_output\"] is not None else None)\n","          mask = data[\"output_mask\"].T.to(device)\n","          weights = data[\"weights\"].T.repeat_interleave(3, dim=0).to(device)\n","\n","          optimizer.zero_grad()\n","\n","          # 2) forward + loss inside autocast for mixed precision\n","          with autocast(\"cuda\"):\n","              kinematics, acc_output, acc_std, gyro_output, gyro_std = model(mocap_data)\n","              loss = criterion(\n","                  kinematics=kinematics * mask * weights,\n","                  acc_mean=acc_output * mask * weights,\n","                  acc_std=acc_std * weights,\n","                  real_acc=real_acc * mask * weights,\n","                  gyro_mean=gyro_output,\n","                  gyro_std=gyro_std,\n","                  real_gyro=real_angular_vel,\n","                  include_gyro=(real_angular_vel is not None)\n","              )\n","\n","          # 3) scale, backward, step\n","          scaler.scale(loss).backward()\n","          scaler.step(optimizer)\n","          scaler.update()\n","\n","          scheduler.step()\n","\n","          curr_loss += loss.item()\n","\n","      return curr_loss / len(train_loader)\n","\n","\n","\n","  def evaluate_model(data_loader):\n","      curr_loss = 0\n","      model.eval()\n","\n","      with torch.no_grad():\n","        for data in data_loader:\n","          data = data[0]\n","          mocap_data = data[\"inputs\"]\n","          real_acc = data[\"accelerations_output\"]\n","          real_angular_vel = data[\"angular_velocities_output\"] if data[\"angular_velocities_output\"] is not None else None\n","          mask = data[\"output_mask\"].T\n","          weights = data[\"weights\"].T.repeat_interleave(3, dim=0)\n","\n","          kinematics, acc_output, acc_std, gyro_output, gyro_std = model(mocap_data)\n","\n","          loss = criterion(kinematics=kinematics * mask * weights,\n","                          acc_mean = acc_output * mask * weights,\n","                          acc_std = acc_std * weights,\n","                          real_acc = real_acc * mask * weights,\n","                          gyro_mean = gyro_output,\n","                          gyro_std = gyro_std,\n","                          real_gyro = real_angular_vel,\n","                          include_gyro = real_angular_vel is not None)\n","\n","\n","          curr_loss += loss.item()\n","\n","      return curr_loss / len(data_loader)\n","\n","\n","  dev_loss_value = evaluate_model(dev_loader)\n","\n","  wandb.log({\"dev_loss\": dev_loss_value})\n","  saver.save_checkpoint(dev_loss_value)\n","\n","  wandb.log({\"train_loss\": evaluate_model(train_loader)})\n","\n","  progress_bar = tqdm(range(EPOCHS), desc=\"Training Progress\", position=0, leave=True)\n","\n","  for epoch in progress_bar:\n","      train_loss = train_model()\n","      wandb.log({\"train_loss\": train_loss})\n","\n","      if (epoch + 1) % 1 == 0:\n","          dev_loss_value = evaluate_model(dev_loader)\n","          saver.save_checkpoint(dev_loss_value)\n","      else:\n","          dev_loss_value = None\n","\n","\n","      # Log the current learning rate\n","      current_lr = optimizer.param_groups[0]['lr']\n","\n","      progress_desc = f\"Epoch {epoch + 1}/{EPOCHS} | Train Loss: {train_loss:.4f} | LR: {current_lr:.12f}\"\n","      if dev_loss_value is not None:\n","          progress_desc += f\" | Dev loss: {dev_loss_value:.4f}\"\n","      progress_bar.set_description(progress_desc)\n","\n","  run.finish()\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"iYzcw3gJOVTb","executionInfo":{"status":"aborted","timestamp":1749147238999,"user_tz":420,"elapsed":713898,"user":{"displayName":"Jayson Meribe","userId":"18347816154755748104"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"mount_file_id":"1vUS-uG07r0AqYCb3zAmDbDBVKrWMeC9D","authorship_tag":"ABX9TyNnMiEL+owS+h13JVuVGLHy"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0a9fe6798b56496b95185d168ad84764":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4b6edd4473d4ef2b80ff8a18ae4693d","IPY_MODEL_363c9885b33e45dfabab6736d39d47f4","IPY_MODEL_b08b0ea16c0b4976970246ffb55ddf8c"],"layout":"IPY_MODEL_b2f29729439f459ea96ef5fc406666fb"}},"f4b6edd4473d4ef2b80ff8a18ae4693d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6c7b5f2fa984966940ea3c5924faf14","placeholder":"​","style":"IPY_MODEL_29fa28ba06a3446aa24ab16ece7c5867","value":"Hyperparameter search:   0%"}},"363c9885b33e45dfabab6736d39d47f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_01d81ca7a6d6454ba47dc29c10f77e22","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48fc7d0a4f2b48d1bd79b7d999beb634","value":0}},"b08b0ea16c0b4976970246ffb55ddf8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d763d299ef62407eb8b8eb0cab12e2ca","placeholder":"​","style":"IPY_MODEL_c73ef0d61c81402ea165dfa207771e25","value":" 0/1 [10:14&lt;?, ?it/s]"}},"b2f29729439f459ea96ef5fc406666fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6c7b5f2fa984966940ea3c5924faf14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29fa28ba06a3446aa24ab16ece7c5867":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01d81ca7a6d6454ba47dc29c10f77e22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48fc7d0a4f2b48d1bd79b7d999beb634":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d763d299ef62407eb8b8eb0cab12e2ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c73ef0d61c81402ea165dfa207771e25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24cee2b5dc374df09f33880cbbe2e155":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0671584f5b044b1a4f0b52c3871e106","IPY_MODEL_481d3de38b0240b88f5b74716f0de037","IPY_MODEL_da5cf922faec4fa885eb376c4dded6fe"],"layout":"IPY_MODEL_8a7c7f8bdde64f498335e83c971397b7"}},"c0671584f5b044b1a4f0b52c3871e106":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ca9fa949f894cc69951bf3df9a8a142","placeholder":"​","style":"IPY_MODEL_9a8cbe06ab824e6c8d0d840aac9acb1d","value":"Epoch 5/100 | Train Loss: -2.4687 | LR: 0.000002730048 | Dev loss: -2.4766:   5%"}},"481d3de38b0240b88f5b74716f0de037":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0e423b1e7714a19ad0f57be5ff94c4c","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f6f548fbac5c48a19d6e0953d60c7d6d","value":5}},"da5cf922faec4fa885eb376c4dded6fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a58957a510849bc984de440425eb495","placeholder":"​","style":"IPY_MODEL_e1356c5568424d4a808b14d89b692396","value":" 5/100 [09:10&lt;2:42:23, 102.56s/it]"}},"8a7c7f8bdde64f498335e83c971397b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ca9fa949f894cc69951bf3df9a8a142":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a8cbe06ab824e6c8d0d840aac9acb1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0e423b1e7714a19ad0f57be5ff94c4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6f548fbac5c48a19d6e0953d60c7d6d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a58957a510849bc984de440425eb495":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1356c5568424d4a808b14d89b692396":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}